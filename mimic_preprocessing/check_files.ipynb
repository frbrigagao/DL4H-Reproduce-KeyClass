{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b771068-5973-444f-874b-ea26ace195a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60841d5a-782e-430f-8f17-67a19c0eae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_csv(filepath, num_rows=5):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, prints the number of records, and displays the first few rows.\n",
    "\n",
    "    Args:\n",
    "        filepath: Path to the CSV file.\n",
    "        num_rows: Number of rows to display (default: 5).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, index_col=0)  # Read CSV, using first column as index\n",
    "        print(f\"File: {filepath}\")\n",
    "        print(f\"Number of records: {len(df)}\")\n",
    "        print(f\"First {num_rows} rows:\\n\")\n",
    "        print(df.head(num_rows))\n",
    "        print(\"-\" * 40)  # Separator for better readability\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e00600fb-7c92-46ce-bf56-ae86a7f8e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    'data/p_icd9NotesDataTable.csv',\n",
    "    'data/p_icd9NotesDataTable_train.csv',\n",
    "    'data/p_icd9NotesDataTable_valid.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476948a4-f819-4a27-a499-00a16484ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/p_icd9NotesDataTable.csv\n",
      "Number of records: 52722\n",
      "First 5 rows:\n",
      "\n",
      "         SUBJECT_ID                                          ICD9_CODE  \\\n",
      "HADM_ID                                                                  \n",
      "100001        58526  25013-3371-5849-5780-V5867-25063-5363-4580-250...   \n",
      "100003        54610  53100-2851-07054-5715-45621-53789-4019-53550-7823   \n",
      "100006         9895   49320-51881-486-20300-2761-7850-3090-V1251-V1582   \n",
      "100007        23018                           56081-5570-9973-486-4019   \n",
      "100009          533  41401-99604-4142-25000-27800-V8535-4148-4111-V...   \n",
      "\n",
      "          CHARTDATE DESCRIPTION  \\\n",
      "HADM_ID                           \n",
      "100001   2117-09-17      Report   \n",
      "100003   2150-04-21      Report   \n",
      "100006   2108-04-17      Report   \n",
      "100007   2145-04-07      Report   \n",
      "100009   2162-05-21      Report   \n",
      "\n",
      "                                                      TEXT  \\\n",
      "HADM_ID                                                      \n",
      "100001   Admission Date:  [**2117-9-11**]              ...   \n",
      "100003   Admission Date:  [**2150-4-17**]              ...   \n",
      "100006   Admission Date:  [**2108-4-6**]       Discharg...   \n",
      "100007   Admission Date:  [**2145-3-31**]              ...   \n",
      "100009   Admission Date:  [**2162-5-16**]              ...   \n",
      "\n",
      "                                                 Level2ICD  \\\n",
      "HADM_ID                                                      \n",
      "100001     250-337-362-403-458-536-578-584-585-707-V13-V58   \n",
      "100003                 070-285-401-456-531-535-537-571-782   \n",
      "100006                 203-276-309-486-493-518-785-V12-V15   \n",
      "100007                                 401-486-557-560-997   \n",
      "100009   250-272-278-285-401-411-414-426-440-996-V15-V4...   \n",
      "\n",
      "                                          TopLevelICD  \n",
      "HADM_ID                                                \n",
      "100001   cat:10-cat:12-cat:19-cat:3-cat:6-cat:7-cat:9  \n",
      "100003                 cat:1-cat:16-cat:4-cat:7-cat:9  \n",
      "100006          cat:16-cat:19-cat:2-cat:3-cat:5-cat:8  \n",
      "100007                       cat:17-cat:7-cat:8-cat:9  \n",
      "100009                cat:17-cat:19-cat:3-cat:4-cat:7  \n",
      "----------------------------------------\n",
      "File: data/p_icd9NotesDataTable_train.csv\n",
      "Number of records: 39541\n",
      "First 5 rows:\n",
      "\n",
      "         SUBJECT_ID                                          ICD9_CODE  \\\n",
      "HADM_ID                                                                  \n",
      "142869         7415  42091-486-4538-5849-27651-2449-2809-4476-2539-...   \n",
      "107834        31364  4280-4240-4254-496-30391-486-42820-41401-3051-...   \n",
      "182354        24774  9729-51881-5849-78550-486-9720-9663-E9504-311-...   \n",
      "143559         9929  9993-3241-5849-7907-4210-40391-2851-4280-3320-...   \n",
      "129268         9576                                   19889-4239-V1011   \n",
      "\n",
      "          CHARTDATE DESCRIPTION  \\\n",
      "HADM_ID                           \n",
      "142869   2189-01-31      Report   \n",
      "107834   2142-10-18      Report   \n",
      "182354   2192-12-08      Report   \n",
      "143559   2114-02-27      Report   \n",
      "129268   2115-09-03      Report   \n",
      "\n",
      "                                                      TEXT  \\\n",
      "HADM_ID                                                      \n",
      "142869   Admission Date:  [**2189-1-16**]              ...   \n",
      "107834   Admission Date:  [**2142-10-5**]              ...   \n",
      "182354   Admission Date:  [**2192-12-3**]              ...   \n",
      "143559   Admission Date:  [**2114-2-12**]              ...   \n",
      "129268   Admission Date:  [**2115-8-27**]       Dischar...   \n",
      "\n",
      "                                                 Level2ICD  \\\n",
      "HADM_ID                                                      \n",
      "142869   244-253-276-280-420-447-453-486-493-584-710-79...   \n",
      "107834             303-305-414-416-424-425-428-440-486-496   \n",
      "182354            311-401-486-493-518-584-785-966-972-E950   \n",
      "143559   041-285-293-324-332-403-421-427-428-584-721-79...   \n",
      "129268                                         198-423-V10   \n",
      "\n",
      "                                               TopLevelICD  \n",
      "HADM_ID                                                     \n",
      "142869   cat:10-cat:13-cat:16-cat:19-cat:3-cat:4-cat:7-...  \n",
      "107834                                   cat:5-cat:7-cat:8  \n",
      "182354       cat:10-cat:16-cat:17-cat:18-cat:5-cat:7-cat:8  \n",
      "143559   cat:1-cat:10-cat:13-cat:16-cat:17-cat:19-cat:4...  \n",
      "129268                                  cat:19-cat:2-cat:7  \n",
      "----------------------------------------\n",
      "File: data/p_icd9NotesDataTable_valid.csv\n",
      "Number of records: 13181\n",
      "First 5 rows:\n",
      "\n",
      "         SUBJECT_ID                                          ICD9_CODE  \\\n",
      "HADM_ID                                                                  \n",
      "105588         1027  25041-40391-99681-25051-36201-5363-2449-2720-V180   \n",
      "154542         9687                         41011-41401-4280-2724-6011   \n",
      "167431        70478                         5712-45620-5723-3051-30501   \n",
      "135712        25328          41011-4280-4240-5990-41401-25000-412-4019   \n",
      "120021         6708                    5789-2851-53550-72252-311-49390   \n",
      "\n",
      "          CHARTDATE DESCRIPTION  \\\n",
      "HADM_ID                           \n",
      "105588   2148-05-13      Report   \n",
      "154542   2143-04-10      Report   \n",
      "167431   2110-01-27      Report   \n",
      "135712   2183-03-20      Report   \n",
      "120021   2150-05-31      Report   \n",
      "\n",
      "                                                      TEXT  \\\n",
      "HADM_ID                                                      \n",
      "105588   Admission Date:  [**2148-5-7**]     Discharge ...   \n",
      "154542   Admission Date:  [**2143-4-7**]              D...   \n",
      "167431   Admission Date:  [**2110-1-22**]              ...   \n",
      "135712   Admission Date:  [**2183-3-10**]       Dischar...   \n",
      "120021   Admission Date:  [**2150-5-28**]     Discharge...   \n",
      "\n",
      "                               Level2ICD  \\\n",
      "HADM_ID                                    \n",
      "105588   244-250-272-362-403-536-996-V18   \n",
      "154542               272-410-414-428-601   \n",
      "167431                   305-456-571-572   \n",
      "135712   250-401-410-412-414-424-428-599   \n",
      "120021           285-311-493-535-578-722   \n",
      "\n",
      "                                   TopLevelICD  \n",
      "HADM_ID                                         \n",
      "105588   cat:17-cat:19-cat:3-cat:6-cat:7-cat:9  \n",
      "154542                      cat:10-cat:3-cat:7  \n",
      "167431                       cat:5-cat:7-cat:9  \n",
      "135712                      cat:10-cat:3-cat:7  \n",
      "120021          cat:13-cat:4-cat:5-cat:8-cat:9  \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for path in file_paths:\n",
    "    if \".txt\" in path: #training_data.txt does not have any headers.\n",
    "        try:\n",
    "            with open(path, 'r') as file:\n",
    "                print(f\"File: {path}\")\n",
    "                # Count lines in the file\n",
    "                line_count = 0\n",
    "                first_lines = []\n",
    "                for i, line in enumerate(file):\n",
    "                    line_count += 1\n",
    "                    if i < 5:  # store first 5 lines\n",
    "                        first_lines.append(line.strip())\n",
    "                print(f\"Number of records: {line_count}\")\n",
    "                print(f\"First 5 rows:\\n\")\n",
    "                for l in first_lines:\n",
    "                    print(l)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {path}: {e}\")\n",
    "        print(\"-\" * 40)  # Separator for better readability\n",
    "\n",
    "    else:\n",
    "        inspect_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ba855ea-6312-4a9f-8154-29ed18e0943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_csv_files(file1_path, file2_path, key_columns, exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Compares two CSV files record by record, focusing on specified key columns\n",
    "    to identify differences.  Lists records from both files sharing the same\n",
    "    key values as the differing records.  Option to exclude columns from the comparison.\n",
    "\n",
    "    Args:\n",
    "        file1_path (str): Path to the first CSV file (R output).\n",
    "        file2_path (str): Path to the second CSV file (Python output).\n",
    "        key_columns (list): List of column names to use as keys for comparing records (e.g., ['HADM_ID', 'SUBJECT_ID']).\n",
    "        exclude_columns (list, optional): List of column names to exclude from the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing records that are different between the two files.\n",
    "                          Returns an empty DataFrame if no differences are found.  Also prints\n",
    "                          related records.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Read CSV files into pandas DataFrames\n",
    "        df1 = pd.read_csv(file1_path)\n",
    "        df2 = pd.read_csv(file2_path)\n",
    "\n",
    "        # Print record counts before comparison\n",
    "        print(f\"Record count in {file1_path}: {len(df1)}\")\n",
    "        print(f\"Record count in {file2_path}: {len(df2)}\")\n",
    "\n",
    "        # Ensure key columns exist in both DataFrames\n",
    "        for col in key_columns:\n",
    "            if col not in df1.columns or col not in df2.columns:\n",
    "                raise ValueError(f\"Key column '{col}' not found in one or both files.\")\n",
    "\n",
    "        # Exclude specified columns\n",
    "        if exclude_columns:\n",
    "            for col in exclude_columns:\n",
    "                if col in df1.columns:\n",
    "                    df1 = df1.drop(col, axis=1)\n",
    "                if col in df2.columns:\n",
    "                    df2 = df2.drop(col, axis=1)\n",
    "\n",
    "        # Convert DataFrames to string format before merging and comparison\n",
    "        df1 = df1.astype(str)\n",
    "        df2 = df2.astype(str)\n",
    "\n",
    "        # Merge the DataFrames using the specified key columns as the join key\n",
    "        merged_df = pd.merge(df1, df2, on=key_columns, how='outer', indicator=True)\n",
    "\n",
    "        # Filter for records that are present in only one of the DataFrames\n",
    "        different_records = merged_df[merged_df['_merge'] != 'both']\n",
    "\n",
    "        if not different_records.empty:\n",
    "            print(\"\\nSummary of Differences:\")\n",
    "            print(different_records['_merge'].value_counts())\n",
    "\n",
    "            print(\"\\nDifferent Records:\")\n",
    "            print(different_records)\n",
    "\n",
    "            # Identify keys (HADM_ID, SUBJECT_ID) of different records from Python output\n",
    "            python_extra_keys = different_records[different_records['_merge'] == 'right_only'][key_columns]\n",
    "\n",
    "            # List records from Python file that share those keys\n",
    "            if not python_extra_keys.empty:\n",
    "                print(\"\\nRecords from Python file sharing keys with extra records:\")\n",
    "                for index, row in python_extra_keys.iterrows():\n",
    "                    # Build query string\n",
    "                    query_parts = []\n",
    "                    for key_col in key_columns:\n",
    "                        query_parts.append(f\"`{key_col}` == '{row[key_col]}'\")  # Escape column names\n",
    "                    query = ' and '.join(query_parts)\n",
    "                    print(f\"\\nRecords in Python file with {key_columns} == {row.to_dict()}:\")\n",
    "                    print(df2.query(query))\n",
    "\n",
    "            # Identify keys (HADM_ID, SUBJECT_ID) of different records from R output\n",
    "            r_extra_keys = different_records[different_records['_merge'] == 'left_only'][key_columns]\n",
    "\n",
    "            # List records from R file that share those keys\n",
    "            if not r_extra_keys.empty:\n",
    "                print(\"\\nRecords from R file sharing keys with extra records:\")\n",
    "                for index, row in r_extra_keys.iterrows():\n",
    "                    # Build query string\n",
    "                    query_parts = []\n",
    "                    for key_col in key_columns:\n",
    "                        query_parts.append(f\"`{key_col}` == '{row[key_col]}'\")  # Escape column names\n",
    "                    query = ' and '.join(query_parts)\n",
    "                    print(f\"\\nRecords in R file with {key_columns} == {row.to_dict()}:\")\n",
    "                    print(df1.query(query))\n",
    "        else:\n",
    "            print(\"\\nNo differences found between the files.\")\n",
    "\n",
    "        return different_records  # Return the DataFrame containing different records\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: One or both of the specified files were not found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of an error\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21eddfd5-a8b5-4285-b13c-de0dec5d1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths to the CSV files you want to compare\n",
    "file1_path = 'data/icd9NotesDataTable.csv'  # Path to the CSV file generated by the R script\n",
    "file2_path = 'data/p_icd9NotesDataTable.csv'  # Path to the CSV file generated by the Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0806234-3c9a-4ce3-9848-7cfb4f610178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: One or both of the specified files were not found.\n",
      "\n",
      "No differences found between the files.\n"
     ]
    }
   ],
   "source": [
    "# Specify the key columns to use for comparing records (adjust as needed)\n",
    "key_columns = ['HADM_ID', 'SUBJECT_ID']  # Columns that uniquely identify each record\n",
    "\n",
    "# Specify the columns to exclude from the comparison\n",
    "exclude_columns = ['TEXT']  # List of columns to exclude\n",
    "\n",
    "# Compare the CSV files and get the DataFrame of different records\n",
    "different_records_df = compare_csv_files(file1_path, file2_path, key_columns, exclude_columns)\n",
    "\n",
    "# Optionally, save the DataFrame of different records to a CSV file\n",
    "if not different_records_df.empty:\n",
    "    different_records_df.to_csv('data/different_records.csv', index=False)\n",
    "    print(\"\\nDifferent records saved to 'data/different_records.csv'\")\n",
    "else:\n",
    "    print(\"\\nNo differences found between the files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a8b3eca-d147-42ee-a13b-3545db87a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in 'data/train.txt': 39541\n",
      "Number of records in 'data/train_labels.txt': 39541\n",
      "Number of records in 'data/valid.txt': 13181\n",
      "Number of records in 'data/valid_labels.txt': 13181\n"
     ]
    }
   ],
   "source": [
    "def count_records(file_path):\n",
    "    \"\"\"\n",
    "    Counts the number of records (lines) in a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of records in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            record_count = sum(1 for line in f)  # Efficiently count lines\n",
    "        return record_count\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while counting records in '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Define the paths to the text files\n",
    "train_text_file = 'data/train.txt'\n",
    "train_labels_file = 'data/train_labels.txt'\n",
    "valid_text_file = 'data/valid.txt'\n",
    "valid_labels_file = 'data/valid_labels.txt'\n",
    "\n",
    "# Count the records in each file\n",
    "train_text_count = count_records(train_text_file)\n",
    "train_labels_count = count_records(train_labels_file)\n",
    "valid_text_count = count_records(valid_text_file)\n",
    "valid_labels_count = count_records(valid_labels_file)\n",
    "\n",
    "# Print the results\n",
    "if train_text_count is not None:\n",
    "    print(f\"Number of records in '{train_text_file}': {train_text_count}\")\n",
    "if train_labels_count is not None:\n",
    "    print(f\"Number of records in '{train_labels_file}': {train_labels_count}\")\n",
    "if valid_text_count is not None:\n",
    "    print(f\"Number of records in '{valid_text_file}': {valid_text_count}\")\n",
    "if valid_labels_count is not None:\n",
    "    print(f\"Number of records in '{valid_labels_file}': {valid_labels_count}\")\n",
    "\n",
    "# Verify if the counts match between text and labels files\n",
    "if (train_text_count is not None and train_labels_count is not None and\n",
    "    train_text_count != train_labels_count):\n",
    "    print(\"Warning: Number of records in train.txt and train_labels.txt do not match!\")\n",
    "\n",
    "if (valid_text_count is not None and valid_labels_count is not None and\n",
    "    valid_text_count != valid_labels_count):\n",
    "    print(\"Warning: Number of records in valid.txt and valid_labels.txt do not match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "243a8aba-81d3-4ca6-b0be-96619d0752cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def count_categories_by_subject(filename):\n",
    "    \"\"\"\n",
    "    1. Reads 'filename' as a CSV.\n",
    "    2. Gathers all unique 'TopLevelICD' categories (which may be comma-separated)\n",
    "       for each SUBJECT_ID.\n",
    "    3. Counts how many unique subjects have each category.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Accumulate categories by subject\n",
    "    subject_categories = defaultdict(set)\n",
    "    counter = 0\n",
    "    \n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        for row in reader:\n",
    "            counter = counter + 1\n",
    "            subject_id = int(row['HADM_ID'])\n",
    "            #print(subject_id)\n",
    "            #subject_id = counter\n",
    "            \n",
    "            # Ensure we handle potential multiple comma-separated categories\n",
    "            category_string = row['TopLevelICD'].strip()\n",
    "            if category_string:\n",
    "                categories = [cat.strip() for cat in category_string.split('-')]\n",
    "                # Add these categories to the subject's set\n",
    "                for cat in categories:\n",
    "                    cat_number = int(cat.split(\"cat:\")[1])\n",
    "                    subject_categories[subject_id].add(cat_number)\n",
    "\n",
    "    # Step 2: Count how many subjects have each category\n",
    "    category_counts = Counter()\n",
    "    for subject_id, categories_set in subject_categories.items():\n",
    "        for cat in categories_set:\n",
    "            category_counts[cat] += 1\n",
    "\n",
    "    # Step 3: Calculate total number of unique subjects\n",
    "    total_subjects = len(subject_categories)\n",
    "    print(f'Total groups: {total_subjects}')\n",
    "    \n",
    "    # Step 4: Print results (count and prevalence), sorted by category name\n",
    "    print(\"Count of subjects per category (TopLevelICD) and prevalence (%), sorted by category:\")\n",
    "    for category in sorted(category_counts):\n",
    "        count = category_counts[category]\n",
    "        prevalence = (count / total_subjects) * 100\n",
    "        print(f\"{category}: {count} subjects ({prevalence:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a13bee98-6e8d-4c32-854d-17e473e11529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total groups: 36905\n",
      "Count of subjects per category (TopLevelICD) and prevalence (%), sorted by category:\n",
      "1: 9957 subjects (26.98%)\n",
      "2: 5960 subjects (16.15%)\n",
      "3: 24198 subjects (65.57%)\n",
      "4: 13332 subjects (36.13%)\n",
      "5: 11006 subjects (29.82%)\n",
      "6: 9355 subjects (25.35%)\n",
      "7: 2597 subjects (7.04%)\n",
      "8: 28931 subjects (78.39%)\n",
      "9: 17202 subjects (46.61%)\n",
      "10: 14333 subjects (38.84%)\n",
      "11: 14817 subjects (40.15%)\n",
      "12: 100 subjects (0.27%)\n",
      "13: 4102 subjects (11.12%)\n",
      "14: 6793 subjects (18.41%)\n",
      "15: 1991 subjects (5.39%)\n",
      "16: 2615 subjects (7.09%)\n",
      "17: 13642 subjects (36.97%)\n",
      "18: 15272 subjects (41.38%)\n",
      "19: 11130 subjects (30.16%)\n",
      "20: 20528 subjects (55.62%)\n"
     ]
    }
   ],
   "source": [
    "csv_filename = 'data/p_icd9NotesDataTable_train.csv'\n",
    "count_categories_by_subject(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8121f84a-30a5-42b0-96e2-e94844b920c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total groups: 52722\n",
      "Count of subjects per category (TopLevelICD) and prevalence (%), sorted by category:\n",
      "1: 14212 subjects (26.96%)\n",
      "2: 8579 subjects (16.27%)\n",
      "3: 34600 subjects (65.63%)\n",
      "4: 19006 subjects (36.05%)\n",
      "5: 15731 subjects (29.84%)\n",
      "6: 15377 subjects (29.17%)\n",
      "7: 41335 subjects (78.40%)\n",
      "8: 24577 subjects (46.62%)\n",
      "9: 20430 subjects (38.75%)\n",
      "10: 21253 subjects (40.31%)\n",
      "11: 156 subjects (0.30%)\n",
      "12: 5924 subjects (11.24%)\n",
      "13: 9808 subjects (18.60%)\n",
      "14: 2805 subjects (5.32%)\n",
      "15: 3713 subjects (7.04%)\n",
      "16: 19498 subjects (36.98%)\n",
      "17: 21865 subjects (41.47%)\n",
      "18: 15969 subjects (30.29%)\n",
      "19: 29312 subjects (55.60%)\n"
     ]
    }
   ],
   "source": [
    "csv_filename = 'data/icd9NotesDataTable.csv'\n",
    "count_categories_by_subject(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7afba83-d77e-4daf-8d15-d5639b654586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "print(eval(\"1-15e-2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ba337-0fb6-45dc-ada3-44f11ecc20af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
