# KeyClass: Text Classification with Label-Descriptions Only

This repository is an attempt at reproducing the paper [Classifying Unstructured Clinical Notes via Automatic Weak Supervision](https://arxiv.org/pdf/2206.12088) for the CS598 - Deep Learning for Healthcare class at UIUC Spring 2025. 

The original code for the paper was obtained from the authors' Github repository: https://github.com/autonlab/KeyClass

**This version includes modifications to attempt to support multi-label classification, specifically for the MIMIC-III dataset, as described in the paper but not included in the original code repository.**

# 1. Repository Structure

- `assets`: images used in this README file.
- `config_files`: `.yaml` configuration files used for each reproducibility test. Includes `config_mimic.yml` (**NEW**) for MIMIC-III.
- `keyclass`: original KeyClass implementation with adaptations for multi-label support.
- `mimic_preprocessing`: **NEW:** Scripts to pre-process the original MIMIC-III csv files into the required format.
    - `00_generate_icd9_descriptors.py`: Generates keyword descriptors for ICD-9 categories (results already included in `config_mimic_unfiltered.yml` and `config_mimic_filtered.yml`).
    - `01_create_admission_note_table.R`: R script to process raw MIMIC CSVs and generate intermediate files.
    - `02_generate_mimic_train_test_files.py`: Python script to convert intermediate files into `train.txt`, `test.txt`, `train_labels.txt`, `test_labels.txt` with multi-hot encoding for MIMIC.
    - `03_icd9_mimic_assigment_analysis.py`: Optional script for analyzing category distribution.
    - `mimic_csv_files/`: Directory where raw MIMIC CSVs should be placed.
    - `intermediate_files/`: Directory for intermediate files generated by the R script.
    - `output_mimic_files/`: **NEW:** Directory where the final preprocessed MIMIC text and label files will be saved by `02_generate_mimic_train_test_files.py`.
- `original_data`: Original datasets for training and evaluation (single-label benchmarks).
    - A subfolder for each dataset `imdb`, `amazon`, `dbpedia`, and `agnews`.
- `pretrained_models`: Pre-trained models provided by the researchers (for benchmark datasets).
- `results`: Results for each training run (one folder for each run).
    - Contains subfolders `/embeddings`, `/metrics`, and `/models`.
- `logs`: Stores logs for each training run.
- `scripts`: Helpful scripts to run the code. Adapted from the original source code. Includes scripts for running experiments.
- `pyproject.toml`: Project configuration file used by `uv` python package manager.
- `README.md`: this README file.

# 2. Requirements

## 2.1 Hardware Requirements

The project was tested on Linux machines running Debian/Ubuntu, with a 32-core CPU, an RTX 4090 GPU 24GB, and at least 128-256 GB of RAM (256GB for some experiments).
MIMIC-III experiments, especially with larger models like BlueBERT, can be memory-intensive.

## 2.2 Environment Setup

First, have **CUDA 12.4+**  installed on the system. A guideline is available on the [Nvidia website](https://developer.nvidia.com/cuda-12-4-0-download-archive). 

Install the `uv` python package manager, available at https://github.com/astral-sh/uv.

On Debian/Ubuntu, run this command to install the dependencies to compile the `slycot` package and to run R scripts (required for MIMIC dataset preprocessing):
``` shell
sudo apt install gfortran liblapack-dev libopenblas-dev
sudo apt install r-base r-base-dev
sudo apt install r-cran-stringr r-cran-data.table r-cran-dplyr r-cran-lubridate r-cran-caret r-cran-tibble
```
*(Note: If you encounter issues installing R packages via apt, you might need to install them within R itself using `install.packages(c("stringr", "data.table", ...))`)*

After the previous command completes, **within the project folder**, run:

- `source .venv/bin/activate` to activate the project's virtual environment.
- `uv sync` to install the necessary python packages. 

*If you want to use another python environment (conda or pip), the necessary packages are listed in the `pyproject.toml` file.*

In addition, this project supports [Weights & Biases](https://wandb.ai/) for model training tracking. If you want to use this feature, please first create your account and authenticate with the API key using `uvx wandb login`.

## 2.3 Getting the Benchmark Datasets, Original Models, and Results

To download the **benchmark datasets** (imdb, amazon, agnews, dbpedia), original pre-trained models (for benchmarks), and results (for benchmarks), run this command:
```shell
cd scripts # Must be in the scripts folder 
uv run get_data.py
``` 

The script will ask for confirmation before dowloading each file. **Atention**: this script will **not** provide the MIMIC-3 dataset.

## 2.4 MIMIC-3 Dataset Preprocessing

KeyClass pipeline requires the MIMIC-III dataset to be preprocessed before running experiments using config_mimic.yml.

**Steps:**

1.**Obtain MIMIC-III**: You must obtain the MIMIC-III Clinical Database (v1.4 or compatible) through the official process (https://mimic.physionet.org/). This requires completing training and signing a data use agreement.

2.**Place Raw Files**: Copy the `DIAGNOSES_ICD.csv` and `NOTEEVENTS.csv` files from the MIMIC-III dataset into the `mimic_preprocessing/mimic_csv_files/` directory.

3.**Generate ICD-9 Descriptors (optional)**: The descriptors are already included in the `/config_files/config_mimic_unfiltered.yml` and `/config_files/config_mimic_filtered.yml`. However, if you want to manually generate them, run the following script:
```shell
cd mimic_preprocessing # Navigate to the preprocessing directory
# This will output the top 30 keywords per ICD-9 top-level category and save the results to target_icd9_descriptors.txt
uv run 00_generate_icd9_descriptors.py --num_keywords_per_cat 30 --output_file target_icd9_descriptors.txt 
```
The script also accepts filtering common keywords that are common in over % percentage of the categories.
In the `config_mimic_filtered.yml` we use the top 30 keywords per category after removing common keywords that were shared in over 30% of the 19 categories. The list was generated with this command:
```shell
cd mimic_preprocessing # Navigate to the preprocessing directory
uv run 00_generate_icd9_descriptors.py --num_keywords_per_cat 30 --shared_keyword_threshold 30 --output_file target_icd9_descriptors_filtered.txt
```
The main idea is to remove overly common words to facilitate distinction between top-level ICD-9 categories.

3.**Run R Script**: Execute the R script to process the raw MIMIC-III CSV files (`DIAGNOSES_ICD.csv` and `NOTEEVENTS.csv`) and create intermediate files. The script filters discharge notes, extracts the associated ICD-9 codes, maps these codes to top-level categories, and splits the data into training and testing sets.
```shell
cd mimic_preprocessing # Navigate to the preprocessing directory
Rscript 01_create_admission_note_table.R
```
This will generate `icd9NotesDataTable_train.csv` and `icd9NotesDataTable_test.csv` in the `mimic_preprocessing/intermediate_files/` directory.

**Credit: Original script from the [FasTag](https://github.com/rivas-lab/FasTag/tree/master/src/textPreprocessing) Github repository [(Venkataraman et al. (2020)](https://doi.org/10.1371/journal.pone.0234647). Adapted for the current project.**

4.**Data Analysis & Visualizations (optional)**: We provide an optional Jupyter notebook that explores the files generated on step 3. To start Jupyter/JupyterLab on the project folder, run the following command:
```shell
uv run --with jupyter jupyter lab
```
Open the web link on your browser and navigate to `/mimic_preprocessing/mimic_data_visualization.ipynb`.

5.**Run Python Script**: Execute the Python script to convert the intermediate files into the final format required by the KeyClass pipeline (text files and multi-hot encoded labels).
```shell
cd mimic_preprocessing # Navigate to the preprocessing directory
uv run 02_generate_mimic_train_test_files.py
```
This will create the following files in the `mimic_preprocessing/output_mimic_files/` directory:
- `train.txt`: Training clinical notes (one per line).
- `test.txt`: Testing clinical notes (one per line).
- `train_labels.txt`: Multi-hot encoded labels for training data (e.g., "010...1").
- `test_labels.txt`: Multi-hot encoded labels for testing data.
- `labels.txt`: Names of the 19 top-level ICD-9 categories.

6.**Copy Output Files**: Copy the output files from the `mimic_preprocessing/output_mimic_files/mimic` to `../original_data/mimic` folder.
```shell
# Creates the destination folder if it does not exist
mkdir -p ../original_data/mimic
# Copies the generated files to the folder (will ask for confirmation if there are files in the destination)
cp -ir output_mimic_files/mimic/* ../original_data/mimic/
```

# 3. Training

To train a single model with the configuration parameters established in the original paper (or modified for experiments), choose one of the `.yaml` configuration files in `/config_files/` (e.g., `config_imdb.yml` for IMDb or `config_mimic.yml` for MIMIC-III after preprocessing) and run this command:
``` shell
cd scripts # Need to be in the /scripts folder 
# Example for IMDB (use this for imdb, amazon, dbpedia, and agnews datasets - single label problems):
uv run run_all.py --config ../config_files/config_imdb.yml --use_wandb 1 # if Weights & Biases is set up
uv run run_all.py --config ../config_files/config_imdb.yml --use_wandb 0 # if Weights & Biases is NOT set up

# Example for MIMIC-III (ensure preprocessing is done first):
uv run run_all_multilabel_.py --config ../config_files/config_mimic.yml --use_wandb 1 # if Weights & Biases is set up
uv run run_all_multilabel.py --config ../config_files/config_mimic.yml --use_wandb 0 # if Weights & Biases is NOT set up
```

# 4. Ablations/Extensions

## 4.1 Experiment 1 - Testing different batch sizes and learning rates

This experiment tests various learning rates and batch sizes for the benchmark datasets.
```shell
cd scripts # Need to be in the /scripts folder 
uv run run_experiments_1.py --use_wandb --keep_configs # If you want Weights & Biases logging and to keep the temporary config files.
uv run run_experiments_1.py # Only local logs
```

**Attention**: This script might take **several days** to complete due to the number of experiments.

## 4.2 Experiment 2 - Testing different number of labeling functions for DBPedia dataset 

This experiment tests varying numbers of labeling functions (topk) for selected datasets (currently configured primarily for DBPedia).
```shell
cd scripts # Need to be in the /scripts folder
uv run run_experiments_2.py --use_wandb --keep_configs # If you want Weights & Biases logging and to keep the temporary config files.
# uv run run_experiments_2.py # Only local logs
```

# 5. Evaluation

Model evaluation (accuracy, precision, recall, F1) is performed automatically at the end of the training process in `run_all.py` (specifically within `train_downstream_model.py`). 

Results are saved in the corresponding `results/<experiment_name>/metrics/` directory and logged to the console (and Weights & Biases if enabled).

# 6. Pre-trained Models

You can download pretrained models **for the benchmark datasets** using the `scripts/get_data.py` script (see Section 2.3).

# 7. Results

Reproducibility results compared to the original paper's will be documented here or in separate analysis files/reports as experiments complete. 


# 7. License and Contributing 

MIT License

Copyright (c) 2022 Carnegie Mellon University, Auton Lab.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

See [MIT LICENSE](https://github.com/autonlab/KeyClass/blob/main/LICENSE) in the original repository for details.